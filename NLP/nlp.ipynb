{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T08:18:00.464316Z",
     "start_time": "2025-04-03T08:17:58.585058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Charger le modèle de langue en français (ou en anglais)\n",
    "nlp = spacy.load(\"fr_core_news_sm\")  # Pour le français, sinon \"en_core_web_sm\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Nettoie le texte en supprimant les stopwords et en lemmatisant.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    clean_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "    return clean_text\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    \"\"\"Génère un résumé du texte avec la méthode LSA (Latent Semantic Analysis).\"\"\"\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"french\"))  # Adapter à la langue\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "text = \"\"\"L'intelligence artificielle révolutionne de nombreux domaines, notamment le traitement du langage naturel.\n",
    "Les modèles de NLP permettent d'analyser, comprendre et générer du texte avec une précision impressionnante.\n",
    "Cela ouvre la porte à de nombreuses applications comme les chatbots, la traduction automatique et le résumé de texte.\n",
    "\"\"\"\n",
    "\n",
    "# Prétraitement du texte\n",
    "cleaned_text = preprocess_text(text)\n",
    "\n",
    "# Générer un résumé\n",
    "summary = summarize_text(cleaned_text, num_sentences=2)\n",
    "\n",
    "print(\"Résumé :\", summary)\n"
   ],
   "id": "69669cfbba10021c",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msumy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msummarizers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlsa\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LsaSummarizer\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Charger le modèle de langue en français (ou en anglais)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m nlp = \u001B[43mspacy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfr_core_news_sm\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Pour le français, sinon \"en_core_web_sm\"\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpreprocess_text\u001B[39m(text):\n\u001B[32m     10\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Nettoie le texte en supprimant les stopwords et en lemmatisant.\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/40-49 Informatique/40.03 Code/Applications/data-analysis/.venv/lib/python3.12/site-packages/spacy/__init__.py:51\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(name, vocab, disable, enable, exclude, config)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(\n\u001B[32m     28\u001B[39m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[32m     29\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m     34\u001B[39m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001B[32m     35\u001B[39m ) -> Language:\n\u001B[32m     36\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[32m     37\u001B[39m \n\u001B[32m     38\u001B[39m \u001B[33;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     49\u001B[39m \u001B[33;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[32m     50\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m        \u001B[49m\u001B[43menable\u001B[49m\u001B[43m=\u001B[49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/40-49 Informatique/40.03 Code/Applications/data-analysis/.venv/lib/python3.12/site-packages/spacy/util.py:472\u001B[39m, in \u001B[36mload_model\u001B[39m\u001B[34m(name, vocab, disable, enable, exclude, config)\u001B[39m\n\u001B[32m    470\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m OLD_MODEL_SHORTCUTS:\n\u001B[32m    471\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001B[38;5;66;03m# type: ignore[index]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors.E050.format(name=name))\n",
      "\u001B[31mOSError\u001B[39m: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
